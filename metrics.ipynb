{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "- retrain the model to use the result for comparation later"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = model.predict_proba(X_val)[:, 1]\n",
    "# relevanz = y_pred >= 0.5\n",
    "# (relevanz == y_val).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score\n",
    "# accuracy_score(y_val, y_pred >= 0.5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true_positive = ((y_pred >= 0.5) & (y_val == 1)).sum()\n",
    "# false_positive = ((y_pred >= 0.5) & (y_val == 0)).sum()\n",
    "# false_negative = ((y_pred < 0.5) & (y_val == 1)).sum()\n",
    "# true_negative = ((y_pred < 0.5) & (y_val == 0)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion_table = np.array(\n",
    "#      # predict neg    pos\n",
    "#     [[true_negative, false_positive], # actual neg\n",
    "#      [false_negative, true_positive]]) # actual pos\n",
    "\n",
    "# confusion_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion_table / confusion_table.sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision = true_positive / (true_positive + false_positive)\n",
    "# recall = true_positive / (true_positive + false_negative)\n",
    "# precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion_table / confusion_table.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision = true_positive / (true_positive + false_positive)\n",
    "# recall = true_positive / (true_positive + false_negative)\n",
    "# precision, recall"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
